{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation functions \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def relu_prime(x):\n",
    "    return (x > 0).astype(int)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1 - np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss functions\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / y_true.size\n",
    "\n",
    "def hinge(y_true, y_pred):\n",
    "    return np.mean(np.maximum(1 - y_true * y_pred, 0))\n",
    "\n",
    "def hinge_prime(y_true, y_pred):\n",
    "    temp = 1 - y_true * y_pred\n",
    "    return -y_true * (temp > 0) / y_true.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        return sigmoid\n",
    "    if activation == \"relu\":\n",
    "        return relu\n",
    "    if activation == \"tanh\":\n",
    "        return tanh\n",
    "\n",
    "def get_activation_derivative(activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        return sigmoid_prime\n",
    "    if activation == \"relu\":\n",
    "        return relu_prime\n",
    "    if activation == \"tanh\":\n",
    "        return tanh_prime\n",
    "\n",
    "def get_loss(loss):\n",
    "    if loss == \"mse\":\n",
    "        return mse\n",
    "    if loss ==\"hinge\":\n",
    "        return hinge\n",
    "\n",
    "def get_loss_derivative(loss):\n",
    "    if loss == \"mse\":\n",
    "        return mse_prime\n",
    "    if loss ==\"hinge\":\n",
    "        return hinge_prime\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Layer: \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward_propagation(self, input_data):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand(input_size, output_size) - 0.5\n",
    "        self.bias = np.random.rand(1, output_size) - 0.5\n",
    "        \n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = np.dot(self.input, self.weights.T) + self.bias\n",
    "        return self.output\n",
    "    \n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        \n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        \n",
    "        return input_error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class ActivationLayer(Layer):\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    def forward_propagation(self, input_data):\n",
    "        self.input = input_data\n",
    "        self.output = self.activation(self.input)\n",
    "        return self.output\n",
    "\n",
    "    def backward_propagation(self, output_error, learning_rate):\n",
    "        return output_error * self.activation_prime(self.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, epochs=1000, learning_rate=1, loss=\"mse\", activation=\"sigmoid\", hidden_layer_sizes=(10,2)):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss = loss\n",
    "        self.activation = activation\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        \n",
    "        self.layers = []\n",
    "        self.layers.append(FCLayer(784, hidden_layer_sizes[0]))\n",
    "        self.layers.append(ActivationLayer(get_activation(activation), get_activation_derivative(activation)))\n",
    "        for i in range(1, len(hidden_layer_sizes)):\n",
    "            self.layers.append(FCLayer(hidden_layer_sizes[i-1], hidden_layer_sizes[i]))\n",
    "            self.layers.append(ActivationLayer(get_activation(activation), get_activation_derivative(activation)))\n",
    "        self.layers.append(FCLayer(hidden_layer_sizes[-1], 1))\n",
    "        self.layers.append(ActivationLayer(get_activation(activation), get_activation_derivative(activation)))\n",
    "   \n",
    "    def fit(self, X, y):\n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(len(X)):\n",
    "                # forward propagation\n",
    "                output = np.array(X[i])\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward_propagation(output)\n",
    "                \n",
    "                # compute error and loss\n",
    "                loss = get_loss(self.loss)(y[i], output)\n",
    "                \n",
    "                # backward propagation\n",
    "                error = get_loss_derivative(self.loss)(y[i], output)\n",
    "                for layer in reversed(self.layers):\n",
    "                    error = layer.backward_propagation(error, self.learning_rate)\n",
    "                    \n",
    "           \n",
    "            print(\"Epoch:\", epoch, \"Loss:\", loss)\n",
    "                \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            output = np.array(X[i])\n",
    "\n",
    "            for layer in self.layers:\n",
    "                output = layer.forward_propagation(output)\n",
    "            predictions.append(output)\n",
    "        return np.array(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([5, 0, 4, ..., 8, 4, 8], dtype=int64))\n",
      "Valid set: (array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([3, 8, 6, ..., 5, 6, 8], dtype=int64))\n",
      "Test set: (array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([7, 2, 1, ..., 4, 5, 6], dtype=int64))\n",
      "X_train shape: (50000, 784)\n",
      "y_train shape: (50000,)\n",
      "X_valid shape: (10000, 784)\n",
      "y_valid shape: (10000,)\n",
      "X_test shape: (10000, 784)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "train_set, valid_set, test_set = None , None, None \n",
    "with gzip.open('./mnist-1.pkl.gz', 'rb') as f:\n",
    "    train_set, valid_set, test_set  = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# Check that the datasets are loaded correctly\n",
    "print(\"Train set:\", train_set)\n",
    "print(\"Valid set:\", valid_set)\n",
    "print(\"Test set:\", test_set)\n",
    "\n",
    "# Access the train_set variable\n",
    "X_train, y_train = train_set\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "X_valid, y_valid = valid_set\n",
    "print(\"X_valid shape:\", X_valid.shape)\n",
    "print(\"y_valid shape:\", y_valid.shape)\n",
    "\n",
    "X_test, y_test = test_set\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Preprocess validation and test data sets\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# this is under the assumption that the validation data which we loaded earlier is not there in the training data and needs to be appended to the end \n",
    "# we append validation set to the end of the training set so validation fraction can take it as validation data when we do grid search\n",
    "X_train= np.concatenate((X_train,X_valid))\n",
    "y_train= np.concatenate((y_train,y_valid))\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (784,) and (10,784) not aligned: 784 (dim 0) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sanje\\Documents\\GitHub\\cs-559\\S23_CS559_Project2\\Project2.ipynb Cell 11\u001b[0m in \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m net \u001b[39m=\u001b[39m Network()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m net\u001b[39m.\u001b[39;49mfit(X_train,y_train\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# test\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m out \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mpredict(X_train)\n",
      "\u001b[1;32mc:\\Users\\sanje\\Documents\\GitHub\\cs-559\\S23_CS559_Project2\\Project2.ipynb Cell 11\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m output \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(X[i])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     output \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mforward_propagation(output)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# compute error and loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m loss \u001b[39m=\u001b[39m get_loss(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss)(y[i], output)\n",
      "\u001b[1;32mc:\\Users\\sanje\\Documents\\GitHub\\cs-559\\S23_CS559_Project2\\Project2.ipynb Cell 11\u001b[0m in \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_propagation\u001b[39m(\u001b[39mself\u001b[39m, input_data):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput \u001b[39m=\u001b[39m input_data\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights\u001b[39m.\u001b[39;49mT) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sanje/Documents/GitHub/cs-559/S23_CS559_Project2/Project2.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (784,) and (10,784) not aligned: 784 (dim 0) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# network\n",
    "net = Network()\n",
    "\n",
    "# train\n",
    "\n",
    "net.fit(X_train,y_train.reshape(-1, 1))\n",
    "\n",
    "# test\n",
    "out = net.predict(X_train)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_venv",
   "language": "python",
   "name": "tf_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
